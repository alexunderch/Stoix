# --- Anakin config ---

# --- Training ---
seed: 42  # RNG seed.
total_num_envs: 1024  # Total Number of vectorised environments across all actors. Needs to be divisible by the number of actors.
total_timesteps: 1e7 # Set the total environment steps.
# If unspecified, it's derived from num_updates; otherwise, num_updates adjusts based on this value.
num_updates: ~ # Number of updates

# --- Evaluation ---
evaluation_greedy: False # Evaluate the policy greedily. If True the policy will select
  # an action which corresponds to the greatest logit. If false, the policy will sample
  # from the logits.
num_eval_episodes: 128 # Number of episodes to evaluate per evaluation.
num_evaluation: 50 # Number of evenly spaced evaluations to perform during training.
absolute_metric: True # Whether the absolute metric should be computed. For more details
  # on the absolute metric please see: https://arxiv.org/abs/2209.10485


actor:
  device_ids: [0, 1]
  actor_per_device: 4
  envs_per_actor: 3
  traj_len: ${system.rollout_length}


learner:
  device_ids: [2, 3]
